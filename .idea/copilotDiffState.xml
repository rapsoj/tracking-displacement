<?xml version="1.0" encoding="UTF-8"?>
<project version="4">
  <component name="CopilotDiffPersistence">
    <option name="pendingDiffs">
      <map>
        <entry key="$PROJECT_DIR$/scrape_fa/paired_image_dataset.py">
          <value>
            <PendingDiffInfo>
              <option name="filePath" value="$PROJECT_DIR$/scrape_fa/paired_image_dataset.py" />
              <option name="originalContent" value="import os&#10;from PIL import Image, ImageFilter&#10;from torch.utils.data import Dataset&#10;import torch&#10;import numpy as np&#10;from torchvision import transforms&#10;&#10;class PairedImageDataset(Dataset):&#10;    def __init__(self, folder, feat_transform=None, label_transform=None):&#10;&#10;        # Default feature transform: ToTensor&#10;        if feat_transform is None:&#10;            feat_transform = transforms.ToTensor()&#10;        # Default label transform: Gaussian blur + ToTensor&#10;        if label_transform is None:&#10;            class LabelBlur:&#10;                def __call__(self, img):&#10;                    return img.filter(ImageFilter.GaussianBlur(radius=7))&#10;            label_transform = transforms.Compose([&#10;                LabelBlur(),&#10;                transforms.ToTensor(),&#10;                lambda x: x * 20&#10;            ])&#10;        self.folder = folder&#10;        self.feat_transform = feat_transform&#10;        self.label_transform = label_transform&#10;        self.pairs = self._find_pairs()&#10;&#10;    def _find_pairs(self):&#10;        files = os.listdir(self.folder)&#10;        feat_files = [f for f in files if f.endswith('_feat.png')]&#10;        label_files = [f for f in files if f.endswith('_label.png')]&#10;        # Map by base name (without _feat/_label)&#10;        feat_map = {f.replace('_feat.png', ''): f for f in feat_files}&#10;        label_map = {f.replace('_label.png', ''): f for f in label_files}&#10;        # Only keep pairs that exist in both&#10;        common_keys = set(feat_map.keys()) &amp; set(label_map.keys())&#10;        filtered_pairs = []&#10;        for k in sorted(common_keys):&#10;            feat_path = os.path.join(self.folder, feat_map[k])&#10;            label_path = os.path.join(self.folder, label_map[k])&#10;            # Check label image is not all black&#10;            with Image.open(label_path) as label_img:&#10;                label_arr = np.array(label_img)&#10;                if np.all(label_arr == 0):&#10;                    continue  # skip if label is all black&#10;            # Check feature image for &gt;5% black pixels&#10;            with Image.open(feat_path) as feat_img:&#10;                feat_arr = np.array(feat_img)&#10;                total_pixels = feat_arr.size&#10;                black_pixels = np.sum(feat_arr == 0)&#10;                if black_pixels / total_pixels &gt; 0.05:&#10;                    continue  # skip if &gt;5% of feature is black&#10;            filtered_pairs.append((k, feat_map[k], label_map[k]))&#10;        return filtered_pairs&#10;&#10;    def _get_min_label_size(self):&#10;        min_w, min_h = None, None&#10;        for k, _, label_name in self.pairs:&#10;            label_path = os.path.join(self.folder, label_name)&#10;            with Image.open(label_path) as img:&#10;                w, h = img.size&#10;                if min_w is None or w &lt; min_w:&#10;                    min_w = w&#10;                if min_h is None or h &lt; min_h:&#10;                    min_h = h&#10;        # Eliminate left and bottom row of pixels&#10;        min_w = max(1, min_w - 1)&#10;        min_h = max(1, min_h - 1)&#10;        return min_w, min_h&#10;&#10;    def __len__(self):&#10;        return len(self.pairs)&#10;&#10;    def __getitem__(self, idx):&#10;        k, feat_name, label_name = self.pairs[idx]&#10;        feat_path = os.path.join(self.folder, feat_name)&#10;        label_path = os.path.join(self.folder, label_name)&#10;        feat_img = Image.open(feat_path).convert('L')&#10;        label_img = Image.open(label_path).convert('L')&#10;        # Crop to smallest label size, eliminating left and bottom row&#10;        if not hasattr(self, '_min_label_size'):&#10;            self._min_label_size = self._get_min_label_size()&#10;        min_w, min_h = self._min_label_size&#10;        feat_img = feat_img.crop((1, 0, 1 + min_w, min_h))&#10;        label_img = label_img.crop((1, 0, 1 + min_w, min_h))&#10;        if self.feat_transform:&#10;            feat_img = self.feat_transform(feat_img)&#10;        else:&#10;            feat_img = torch.from_numpy(np.array(feat_img)).float().unsqueeze(0) / 255.0&#10;        if self.label_transform:&#10;            label_img = self.label_transform(label_img)&#10;        else:&#10;            label_img = torch.from_numpy(np.array(label_img)).float().unsqueeze(0) / 255.0&#10;        return feat_img, label_img&#10;&#10;# Example usage:&#10;# dataset = PairedImageDataset('/path/to/folder')&#10;# img, label = dataset[0]&#10;" />
              <option name="updatedContent" value="import os&#10;from PIL import Image, ImageFilter&#10;from torch.utils.data import Dataset&#10;import torch&#10;import numpy as np&#10;from torchvision import transforms&#10;&#10;class PairedImageDataset(Dataset):&#10;    def __init__(self, folder, feat_transform=None, label_transform=None):&#10;&#10;        # Default feature transform: ToTensor&#10;        if feat_transform is None:&#10;            feat_transform = transforms.ToTensor()&#10;        # Default label transform: Gaussian blur + ToTensor&#10;        if label_transform is None:&#10;            class LabelBlur:&#10;                def __call__(self, img):&#10;                    return img.filter(ImageFilter.GaussianBlur(radius=7))&#10;            label_transform = transforms.Compose([&#10;                LabelBlur(),&#10;                transforms.ToTensor(),&#10;                lambda x: x * 20&#10;            ])&#10;        self.folder = folder&#10;        self.feat_transform = feat_transform&#10;        self.label_transform = label_transform&#10;        self.pairs = self._find_pairs()&#10;&#10;    def _find_pairs(self):&#10;        files = os.listdir(self.folder)&#10;        feat_files = [f for f in files if f.endswith('_feat.png')]&#10;        label_files = [f for f in files if f.endswith('_label.png')]&#10;        # Map by base name (without _feat/_label)&#10;        feat_map = {f.replace('_feat.png', ''): f for f in feat_files}&#10;        label_map = {f.replace('_label.png', ''): f for f in label_files}&#10;        # Only keep pairs that exist in both&#10;        common_keys = set(feat_map.keys()) &amp; set(label_map.keys())&#10;        filtered_pairs = []&#10;        for k in sorted(common_keys):&#10;            feat_path = os.path.join(self.folder, feat_map[k])&#10;            label_path = os.path.join(self.folder, label_map[k])&#10;            # Check label image is not all black&#10;            with Image.open(label_path) as label_img:&#10;                label_arr = np.array(label_img)&#10;                if np.all(label_arr == 0):&#10;                    continue  # skip if label is all black&#10;            # Check feature image for &gt;5% black pixels&#10;            with Image.open(feat_path) as feat_img:&#10;                feat_arr = np.array(feat_img)&#10;                total_pixels = feat_arr.size&#10;                black_pixels = np.sum(feat_arr == 0)&#10;                if black_pixels / total_pixels &gt; 0.05:&#10;                    continue  # skip if &gt;5% of feature is black&#10;            filtered_pairs.append((k, feat_map[k], label_map[k]))&#10;        return filtered_pairs&#10;&#10;    def _get_min_label_size(self):&#10;        min_w, min_h = None, None&#10;        for k, _, label_name in self.pairs:&#10;            label_path = os.path.join(self.folder, label_name)&#10;            with Image.open(label_path) as img:&#10;                w, h = img.size&#10;                if min_w is None or w &lt; min_w:&#10;                    min_w = w&#10;                if min_h is None or h &lt; min_h:&#10;                    min_h = h&#10;        # Eliminate left and bottom row of pixels&#10;        min_w = max(1, min_w - 1)&#10;        min_h = max(1, min_h - 1)&#10;        return min_w, min_h&#10;&#10;    def __len__(self):&#10;        # 8 augmentations per pair (4 rotations x 2 flips)&#10;        return len(self.pairs) * 8&#10;&#10;    def __getitem__(self, idx):&#10;        # Determine which pair and which augmentation&#10;        pair_idx = idx // 8&#10;        aug_idx = idx % 8&#10;        k, feat_name, label_name = self.pairs[pair_idx]&#10;        feat_path = os.path.join(self.folder, feat_name)&#10;        label_path = os.path.join(self.folder, label_name)&#10;        feat_img = Image.open(feat_path).convert('L')&#10;        label_img = Image.open(label_path).convert('L')&#10;        # Crop to smallest label size, eliminating left and bottom row&#10;        if not hasattr(self, '_min_label_size'):&#10;            self._min_label_size = self._get_min_label_size()&#10;        min_w, min_h = self._min_label_size&#10;        feat_img = feat_img.crop((1, 0, 1 + min_w, min_h))&#10;        label_img = label_img.crop((1, 0, 1 + min_w, min_h))&#10;        # Apply rotation and flip&#10;        rotation = (aug_idx % 4) * 90&#10;        flip = (aug_idx // 4) == 1&#10;        if rotation != 0:&#10;            feat_img = feat_img.rotate(rotation)&#10;            label_img = label_img.rotate(rotation)&#10;        if flip:&#10;            feat_img = feat_img.transpose(Image.FLIP_LEFT_RIGHT)&#10;            label_img = label_img.transpose(Image.FLIP_LEFT_RIGHT)&#10;        if self.feat_transform:&#10;            feat_img = self.feat_transform(feat_img)&#10;        else:&#10;            feat_img = torch.from_numpy(np.array(feat_img)).float().unsqueeze(0) / 255.0&#10;        if self.label_transform:&#10;            label_img = self.label_transform(label_img)&#10;        else:&#10;            label_img = torch.from_numpy(np.array(label_img)).float().unsqueeze(0) / 255.0&#10;        return feat_img, label_img&#10;&#10;# Example usage:&#10;# dataset = PairedImageDataset('/path/to/folder')&#10;# img, label = dataset[0]" />
            </PendingDiffInfo>
          </value>
        </entry>
      </map>
    </option>
  </component>
</project>